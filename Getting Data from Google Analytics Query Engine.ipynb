{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import urllib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Goals: \n",
    "\n",
    "This notebook will help work through the steps required to get some data from a URL and do the data cleansing steps required to use it. \n",
    "\n",
    "* ####Learn how to query using GA Query\n",
    "    * Build a working query to get pageview data for Liftopia.com\n",
    "    * Use this query to\n",
    "* ####Data Cleaning Tricks\n",
    "    * String Manipulation using replace and regex\n",
    "    * Use this query to\n",
    "* ####Use the pd.merge function like a VLOOKUP\n",
    "    * Use a seperate source of data to turn product ID's into product names\n",
    "* ####Convert a string into a Datetime object\n",
    "    * Often dates are complitcated to work, with, learn some quick tips for manipulating dates\n",
    "    \n",
    "________________________________________________\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learn How to Query Using GA Query\n",
    "\n",
    "\n",
    "- Go to [https://ga-dev-tools.appspot.com/query-explorer/](https://ga-dev-tools.appspot.com/query-explorer/)\n",
    "- You'll need to authorize using your Liftopia.com account\n",
    "- Select from the drop downs to make sure you have the following: \n",
    "    <img src=\"assets/gaquery1.png\" width=\"800\" />\n",
    "\n",
    "- The different options there allow you to select which data source you want (Cloud Store and Liftopia have seperate data stores)\n",
    "- Next go through the next options to build a query with the following parameters:\n",
    "    - start-date = 2014-12-01\n",
    "    - end - date = 2013-12-31\n",
    "    - metrics = ga:pageviews\n",
    "        -this says \"Show me pageviews (its like the what in Good Data)\n",
    "    - dimensions = ga:pagepath and ga:date\n",
    "        -this is the \"how\" from GoodData\n",
    "    -sort = ga:pageviews\n",
    "    - filters = ga:pagePath=@product_id\n",
    "        - This filter is using text matching. The @symbol means \"contains substring\". [Here's more info on filtering](https://developers.google.com/analytics/devguides/reporting/core/v3/reference#filters)\n",
    "\n",
    "-Next you should be able to run your query! You should see some results like this: \n",
    "    <img src=\"assets/gaquery2.png\" width=\"800\" />\n",
    "\n",
    "\n",
    "\n",
    "________________________\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ok - great so you managed to get your query working... How do I see the data?!\n",
    "\n",
    "\n",
    "- At the very bottom of the query results, there are some options. One of them contains a link that will give you the results in a JSON file: \n",
    "    <img src=\"assets/gaquery3.png\" width=\"700\" />\n",
    "\n",
    "- Just to see what it looks like. Copy the link from the box and paste it into a new Tab. If you did it right, you should see something like this: \n",
    "    - Note: if the JSON looks ugly, install the chrome plugin JsonView\n",
    "\n",
    "  <img src=\"assets/gaquery4.png\" width=\"700\" />\n",
    "  \n",
    "  \n",
    "-What you've just done is built a URL that can be accessed directly from Python using the  JSON library! \n",
    "-Note, the access key appened to the end of the URL will expire every 60 minutes. So keep that in mind\n",
    "\n",
    "________________________\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accessing that JSON data from Pandas\n",
    "\n",
    "- Now we will build out a method to get the data out of that JSON file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Fill in the code below to make a working URL that gives you the same result as the one you pasted into your browser window\n",
    "access_token = ''\n",
    "start_date = ''\n",
    "end_date =  ''\n",
    "start_index = 1\n",
    "\n",
    "\n",
    "# The back slash symbol at the end of the line used with the + is saying concatenate with the string on the next line\n",
    "# Makes it easier to read the long string\n",
    "url = 'first part of the URL' +\\\n",
    "       'second part of the url %s' %start_date +\\\n",
    "        'third part of the url %s'  %end_date +\\\n",
    "        'more url here...%s' %start_index +\\\n",
    "        'access token here...%s' %access_token\n",
    "        \n",
    "print \"===========Does this match the one you copied from GA Query?=========================\"\n",
    "print \"URL: %s\" %url \n",
    "print \"=====================================================================================\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#To get the data from the URL into a variable We need to use a combination of 2 libraries JSON and URLLIB)\n",
    "#Here's the code:\n",
    "\n",
    "result = json.load(urllib.urlopen(url))\n",
    "\n",
    "#run this cell to see what the JSON looks like\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ok that's pretty ugly...\n",
    "- So at this point we have all the data from the JSON file saved in the variable \"result\" \n",
    "- A JSON file is a dictionary, so you you access portions of it using the following structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'dimensions': u'ga:pagePath,ga:date',\n",
       " u'end-date': u'2014-12-31',\n",
       " u'filters': u'ga:pagePath=@product_id',\n",
       " u'ids': u'ga:1870495',\n",
       " u'max-results': 1000,\n",
       " u'metrics': [u'ga:pageviews'],\n",
       " u'sort': [u'-ga:pageviews'],\n",
       " u'start-date': u'2014-12-01',\n",
       " u'start-index': 1}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['query']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- You can go deeper into a level by adding another key: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'ga:pagePath,ga:date'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['query']['dimensions']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Use your web browser to look at the JSON result and find the key for the data that we want to analyze... (it should have the page name, the date of the pageview and the number of pageviews. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Ok now turn that into a dataframe called df using the column names: 'page_name','view_date','pageviews' : \n",
    "#fill in the code here: \n",
    "df = pd.DataFrame()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Awesome - now we have our GA Query data into  Panadas... let's clean it up a bit\n",
    "- When you have a string, you can use the .split() method to split the string into a list of items before and after the character(s) you wanted to split. On.\n",
    "- Like this: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/product?product_id=4859\n",
      "[u'/produ', u't?produ', u't_id=4859']\n",
      "/produ\n"
     ]
    }
   ],
   "source": [
    "print df['page_name'].ix[1]\n",
    "print df['page_name'].ix[1].split(\"c\")\n",
    "#You can access the items in this list by referencing their index [0] or [1]\n",
    "print df['page_name'].ix[1].split(\"c\")[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Now we are going to use a similar method on the dataframe column:\n",
    "    -Instead of splitting the individual item , we can split a column using df['column name'].str.split()\n",
    "\n",
    "- You're going to want to use .split and maybe even some .replace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    /produ\n",
       "1    /produ\n",
       "2    /produ\n",
       "3    /produ\n",
       "4    /produ\n",
       "Name: page_name, dtype: object"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splits = df.page_name.str.split('c')\n",
    "splits.str[0].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Use this method to create a column in your data fram called \"product_id\" that contains the items between \"product_id=\" and \"&\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#your code here\n",
    "\n",
    "\n",
    "# Use this to see how many values you have\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#check out the unique values:\n",
    "df['product_id'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- There are some values here we will want to remove. \n",
    "    -Take a look at the pagenames for those rows that aren't numbers. They're wierd URLs.. I think we can drop them. \n",
    "    -Lets use a little regex to clean it up.\n",
    "    -Regex is a way to do advanced string manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "df = df[df.product_id.str.contains('^[0-9]+$', flags=re.IGNORECASE, regex=True, na=False)]\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Next lets drop NA values and convert the column to type \"int\" - hint: us .astype()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Your code here\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging with another Dataframe\n",
    "\n",
    "- Ok now we have a clean column of numbers that correspond to the product ID. Now we can use this number and bring in the Product name. I've included a file called 'produc_id_to_product_name.csv'\n",
    "- Use this file along with the pandas \"merge\" functionality to make a new column in the dataframe that shows the product name\n",
    "- Include another column that shows  whether or not the product is dateless."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Your code here\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____________________________\n",
    "### Converting Strings to Dates\n",
    "- The last step is to get the trip date out of the Page name. Use a techinque similar to the Product ID method we used\n",
    "- create a column called df['trip_date'] to hold these values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Your code here\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Inspecting results\n",
    "- some of the values you got are empty... Why? Maybe they are dateless products. \n",
    "- Use some filtering on the dataframe to inspect the rows that have a Null trip_date and are dateless"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#your code here\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#If everything without a date is datelss, we can drop those products. \n",
    "df=df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Now that we have a column with a string containing our date. We can using the Pandas .str methods to get portions of it out. \n",
    "- To convert a Year, Month, Day into a datetime object. We do the following:\n",
    "    - Year * 10000 + Month * 100 + Day\n",
    "    - Then we can use the pd.to_datedtime() to convert. \n",
    "- To get specific portions from a string we use string indexing: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    uct?p\n",
       "1    uct?p\n",
       "2    uct?p\n",
       "3    uct?p\n",
       "4    uct?p\n",
       "Name: page_name, dtype: object"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Example\n",
    "df.page_name.str[5:10].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Use string indexing to get the year, month day from the trip date, multiply by the values shown above, and then convert to a datetime object. \n",
    "- Replace the trip_date column with this new value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Your code here: \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "year = \n",
    "month = \n",
    "day = \n",
    "df.trip_date = pd.to_datetime(year*10000+month*100+day,format='%Y%m%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Save your results to a csv! \n",
    "df.to_csv('ga_query.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Ok... so we've parsed one single page of the JSON... GA Query only gives you 1000 results per page, so we would need to loop through all the pages... thats next! "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
